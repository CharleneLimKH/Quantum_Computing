{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pyswarms as ps\n",
    "from pyswarms.utils.plotters import (plot_cost_history)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras import Sequential\n",
    "from keras.layers import Dense, Dropout\n",
    "from sklearn import preprocessing \n",
    "from scipy.io import arff\n",
    "#from sklearn.metrics import mean_squared_error\n",
    "#from sklearn.metrics import mean_absolute_error\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = arff.loadarff(\"./dataset/Medicaldataset.arff\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>gender</th>\n",
       "      <th>impluse</th>\n",
       "      <th>pressurehight</th>\n",
       "      <th>pressurelow</th>\n",
       "      <th>glucose</th>\n",
       "      <th>kcm</th>\n",
       "      <th>troponin</th>\n",
       "      <th>class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>64.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>66.0</td>\n",
       "      <td>160.0</td>\n",
       "      <td>83.0</td>\n",
       "      <td>160.0</td>\n",
       "      <td>1.80</td>\n",
       "      <td>0.012</td>\n",
       "      <td>b'negative'</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>21.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>94.0</td>\n",
       "      <td>98.0</td>\n",
       "      <td>46.0</td>\n",
       "      <td>296.0</td>\n",
       "      <td>6.75</td>\n",
       "      <td>1.060</td>\n",
       "      <td>b'positive'</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>55.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>64.0</td>\n",
       "      <td>160.0</td>\n",
       "      <td>77.0</td>\n",
       "      <td>270.0</td>\n",
       "      <td>1.99</td>\n",
       "      <td>0.003</td>\n",
       "      <td>b'negative'</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>64.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>70.0</td>\n",
       "      <td>120.0</td>\n",
       "      <td>55.0</td>\n",
       "      <td>270.0</td>\n",
       "      <td>13.87</td>\n",
       "      <td>0.122</td>\n",
       "      <td>b'positive'</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>55.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>64.0</td>\n",
       "      <td>112.0</td>\n",
       "      <td>65.0</td>\n",
       "      <td>300.0</td>\n",
       "      <td>1.08</td>\n",
       "      <td>0.003</td>\n",
       "      <td>b'negative'</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    age  gender  impluse  pressurehight  pressurelow  glucose    kcm  \\\n",
       "0  64.0     1.0     66.0          160.0         83.0    160.0   1.80   \n",
       "1  21.0     1.0     94.0           98.0         46.0    296.0   6.75   \n",
       "2  55.0     1.0     64.0          160.0         77.0    270.0   1.99   \n",
       "3  64.0     1.0     70.0          120.0         55.0    270.0  13.87   \n",
       "4  55.0     1.0     64.0          112.0         65.0    300.0   1.08   \n",
       "\n",
       "   troponin        class  \n",
       "0     0.012  b'negative'  \n",
       "1     1.060  b'positive'  \n",
       "2     0.003  b'negative'  \n",
       "3     0.122  b'positive'  \n",
       "4     0.003  b'negative'  "
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.DataFrame(data[0])\n",
    "\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df.iloc[:,df.columns !='class'] #select all features except for class\n",
    "X_1 = preprocessing.normalize(X, axis=1) #normalizing the features\n",
    "X_1 = pd.DataFrame(X_1, columns=df.columns[:-1])\n",
    "y = df['class'].str.decode('utf-8') #transform target to 0 and 1\n",
    "mapping = {'negative': 0, 'positive': 1}\n",
    "y = y.replace(mapping).to_numpy()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X_1, y, test_size=0.33, random_state=42) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "n_estimators=50, Mean Cross-Validation Score: 0.9863607558474479\n",
      "n_estimators=100, Mean Cross-Validation Score: 0.9863607558474479\n",
      "n_estimators=200, Mean Cross-Validation Score: 0.9863607558474479\n",
      "n_estimators=500, Mean Cross-Validation Score: 0.9856002995736837\n"
     ]
    }
   ],
   "source": [
    "#perform feature extraction\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.feature_selection import SelectFromModel\n",
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "# Loop over different values of n_estimators\n",
    "for n_trees in [50, 100, 200, 500]:\n",
    "    # Create RandomForestClassifier with current n_estimators\n",
    "    forest = RandomForestClassifier(n_estimators=n_trees, random_state=42)\n",
    "    \n",
    "    # Use cross_val_score for evaluation\n",
    "    scores = cross_val_score(forest, X, y, cv=5)  # 5-fold cross-validation\n",
    "    mean_score = scores.mean()\n",
    "    \n",
    "    print(f\"n_estimators={n_trees}, Mean Cross-Validation Score: {mean_score}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "age\n",
      "glucose\n",
      "kcm\n",
      "troponin\n"
     ]
    }
   ],
   "source": [
    "#create and train a random forest\n",
    "forest= RandomForestClassifier(n_estimators= 200, random_state= 42)\n",
    "forest.fit(X_train, y_train)\n",
    "\n",
    "#get the most important features\n",
    "forest_feats= SelectFromModel(forest, threshold= 'median')\n",
    "forest_feats.fit(X_train, y_train)\n",
    "\n",
    "#get training and development sets that have only the most important features\n",
    "x_train_forest= forest_feats.transform(X_train)\n",
    "x_devel_forest= forest_feats.transform(X_test)\n",
    "\n",
    "#see which features were retained\n",
    "for i in forest_feats.get_support(indices= True):\n",
    "    print(X_train.columns[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "           age   glucose       kcm  troponin\n",
      "0     0.248097  0.620242  0.006978  0.000047\n",
      "1     0.063706  0.897957  0.020477  0.003216\n",
      "2     0.164671  0.808387  0.005958  0.000009\n",
      "3     0.202879  0.855896  0.043968  0.000387\n",
      "4     0.162973  0.888944  0.003200  0.000009\n",
      "...        ...       ...       ...       ...\n",
      "1314  0.164247  0.761509  0.006085  0.000022\n",
      "1315  0.288692  0.651745  0.005818  0.000752\n",
      "1316  0.187620  0.400255  0.005170  0.017720\n",
      "1317  0.114900  0.942603  0.012341  0.000764\n",
      "1318  0.203388  0.534391  0.202949  0.007059\n",
      "\n",
      "[1319 rows x 4 columns]\n"
     ]
    }
   ],
   "source": [
    "X_2 = X_1[[\"age\", \"glucose\", \"kcm\", \"troponin\"]]\n",
    "print(X_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X_2, y, test_size=0.33, random_state=42) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "numpy.ndarray"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train = np.array(y_train) #make it numpy array for math operations\n",
    "type(y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "#set up NN architecture\n",
    "n_inputs = 4 #input layer\n",
    "n_hidden = 20 #hidden layer\n",
    "n_classes = 2 #output layer\n",
    "\n",
    "num_samples = 1319 #number of samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "def logits_function(p):\n",
    "    \"\"\" Calculate roll-back the weights and biases\n",
    "\n",
    "    Inputs\n",
    "    ------\n",
    "    p: np.ndarray\n",
    "        The dimensions should include an unrolled version of the\n",
    "        weights and biases.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    numpy.ndarray of logits for layer 2\n",
    "\n",
    "    \"\"\"\n",
    "    # Roll-back the weights and biases\n",
    "    W1 = p[0:80].reshape((n_inputs,n_hidden))\n",
    "    b1 = p[80:100].reshape((n_hidden,))\n",
    "    W2 = p[100:160].reshape((n_hidden,n_classes))\n",
    "    b2 = p[160:163].reshape((n_classes,))\n",
    "\n",
    "    # Perform forward propagation\n",
    "    z1 = X_train.dot(W1) + b1  # Pre-activation in Layer 1\n",
    "    a1 = np.tanh(z1)           # Activation in Layer 1\n",
    "    logits = a1.dot(W2) + b2   # Pre-activation in Layer 2\n",
    "    return logits              # Logits for Layer 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Forward propagation\n",
    "def forward_prop(params):\n",
    "    \"\"\"Forward propagation as objective function\n",
    "\n",
    "    This computes for the forward propagation of the neural network, as\n",
    "    well as the loss.\n",
    "\n",
    "    Inputs\n",
    "    ------\n",
    "    params: np.ndarray\n",
    "        The dimensions should include an unrolled version of the\n",
    "        weights and biases.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    float\n",
    "        The computed negative log-likelihood loss given the parameters\n",
    "    \"\"\"\n",
    "    logits = logits_function(params)\n",
    "   \n",
    "    # Compute for the softmax of the logits\n",
    "    exp_scores = np.exp(logits)\n",
    "    probs = exp_scores / np.sum(exp_scores, axis=1, keepdims=True)\n",
    "    \n",
    "    # Compute for the negative log likelihood\n",
    "\n",
    "    corect_logprobs = -np.log(probs[range(num_samples), y_train])\n",
    "    \n",
    "    loss = np.sum(corect_logprobs) / num_samples\n",
    "    return loss\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "def f(x):\n",
    "    \"\"\"Higher-level method to do forward_prop in the\n",
    "    whole swarm.\n",
    "\n",
    "    Inputs\n",
    "    ------\n",
    "    x: numpy.ndarray of shape (n_particles, dimensions)\n",
    "        The swarm that will perform the search\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    numpy.ndarray of shape (n_particles, )\n",
    "        The computed loss for each particle\n",
    "    \"\"\"\n",
    "    n_particles = x.shape[0]\n",
    "    j = [forward_prop(x[i]) for i in range(n_particles)] #for loop to calculate loss for each particle\n",
    "    return np.array(j)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-22 23:32:16,053 - pyswarms.single.global_best - INFO - Optimize for 2000 iters with {'c1': 0.5, 'c2': 0.3, 'w': 0.9}\n",
      "pyswarms.single.global_best:   0%|          |0/2000\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "cannot reshape array of size 42 into shape (20,2)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "File \u001b[1;32m<timed exec>:9\u001b[0m\n",
      "File \u001b[1;32md:\\FHNW_Medical_Informatics\\Python\\Python_Learn\\Q_C_Project\\.venv\\lib\\site-packages\\pyswarms\\single\\global_best.py:209\u001b[0m, in \u001b[0;36mGlobalBestPSO.optimize\u001b[1;34m(self, objective_func, iters, n_processes, verbose, **kwargs)\u001b[0m\n\u001b[0;32m    205\u001b[0m ftol_history \u001b[39m=\u001b[39m deque(maxlen\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mftol_iter)\n\u001b[0;32m    206\u001b[0m \u001b[39mfor\u001b[39;00m i \u001b[39min\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mrep\u001b[39m.\u001b[39mpbar(iters, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mname) \u001b[39mif\u001b[39;00m verbose \u001b[39melse\u001b[39;00m \u001b[39mrange\u001b[39m(iters):\n\u001b[0;32m    207\u001b[0m     \u001b[39m# Compute cost for current position and personal best\u001b[39;00m\n\u001b[0;32m    208\u001b[0m     \u001b[39m# fmt: off\u001b[39;00m\n\u001b[1;32m--> 209\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mswarm\u001b[39m.\u001b[39mcurrent_cost \u001b[39m=\u001b[39m compute_objective_function(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mswarm, objective_func, pool\u001b[39m=\u001b[39mpool, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[0;32m    210\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mswarm\u001b[39m.\u001b[39mpbest_pos, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mswarm\u001b[39m.\u001b[39mpbest_cost \u001b[39m=\u001b[39m compute_pbest(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mswarm)\n\u001b[0;32m    211\u001b[0m     \u001b[39m# Set best_cost_yet_found for ftol\u001b[39;00m\n",
      "File \u001b[1;32md:\\FHNW_Medical_Informatics\\Python\\Python_Learn\\Q_C_Project\\.venv\\lib\\site-packages\\pyswarms\\backend\\operators.py:239\u001b[0m, in \u001b[0;36mcompute_objective_function\u001b[1;34m(swarm, objective_func, pool, **kwargs)\u001b[0m\n\u001b[0;32m    214\u001b[0m \u001b[39m\u001b[39m\u001b[39m\"\"\"Evaluate particles using the objective function\u001b[39;00m\n\u001b[0;32m    215\u001b[0m \n\u001b[0;32m    216\u001b[0m \u001b[39mThis method evaluates each particle in the swarm according to the objective\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    236\u001b[0m \u001b[39m    Cost-matrix for the given swarm\u001b[39;00m\n\u001b[0;32m    237\u001b[0m \u001b[39m\"\"\"\u001b[39;00m\n\u001b[0;32m    238\u001b[0m \u001b[39mif\u001b[39;00m pool \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m--> 239\u001b[0m     \u001b[39mreturn\u001b[39;00m objective_func(swarm\u001b[39m.\u001b[39mposition, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[0;32m    240\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m    241\u001b[0m     results \u001b[39m=\u001b[39m pool\u001b[39m.\u001b[39mmap(\n\u001b[0;32m    242\u001b[0m         partial(objective_func, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs),\n\u001b[0;32m    243\u001b[0m         np\u001b[39m.\u001b[39marray_split(swarm\u001b[39m.\u001b[39mposition, pool\u001b[39m.\u001b[39m_processes),\n\u001b[0;32m    244\u001b[0m     )\n",
      "\u001b[1;32md:\\FHNW_Medical_Informatics\\Python\\Python_Learn\\Q_C_Project\\PSONN.ipynb Cell 17\u001b[0m line \u001b[0;36m1\n\u001b[0;32m      <a href='vscode-notebook-cell:/d%3A/FHNW_Medical_Informatics/Python/Python_Learn/Q_C_Project/PSONN.ipynb#X15sZmlsZQ%3D%3D?line=1'>2</a>\u001b[0m \u001b[39m\u001b[39m\u001b[39m\"\"\"Higher-level method to do forward_prop in the\u001b[39;00m\n\u001b[0;32m      <a href='vscode-notebook-cell:/d%3A/FHNW_Medical_Informatics/Python/Python_Learn/Q_C_Project/PSONN.ipynb#X15sZmlsZQ%3D%3D?line=2'>3</a>\u001b[0m \u001b[39mwhole swarm.\u001b[39;00m\n\u001b[0;32m      <a href='vscode-notebook-cell:/d%3A/FHNW_Medical_Informatics/Python/Python_Learn/Q_C_Project/PSONN.ipynb#X15sZmlsZQ%3D%3D?line=3'>4</a>\u001b[0m \n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     <a href='vscode-notebook-cell:/d%3A/FHNW_Medical_Informatics/Python/Python_Learn/Q_C_Project/PSONN.ipynb#X15sZmlsZQ%3D%3D?line=12'>13</a>\u001b[0m \u001b[39m    The computed loss for each particle\u001b[39;00m\n\u001b[0;32m     <a href='vscode-notebook-cell:/d%3A/FHNW_Medical_Informatics/Python/Python_Learn/Q_C_Project/PSONN.ipynb#X15sZmlsZQ%3D%3D?line=13'>14</a>\u001b[0m \u001b[39m\"\"\"\u001b[39;00m\n\u001b[0;32m     <a href='vscode-notebook-cell:/d%3A/FHNW_Medical_Informatics/Python/Python_Learn/Q_C_Project/PSONN.ipynb#X15sZmlsZQ%3D%3D?line=14'>15</a>\u001b[0m n_particles \u001b[39m=\u001b[39m x\u001b[39m.\u001b[39mshape[\u001b[39m0\u001b[39m]\n\u001b[1;32m---> <a href='vscode-notebook-cell:/d%3A/FHNW_Medical_Informatics/Python/Python_Learn/Q_C_Project/PSONN.ipynb#X15sZmlsZQ%3D%3D?line=15'>16</a>\u001b[0m j \u001b[39m=\u001b[39m [forward_prop(x[i]) \u001b[39mfor\u001b[39;00m i \u001b[39min\u001b[39;00m \u001b[39mrange\u001b[39m(n_particles)] \u001b[39m#for loop to calculate loss for each particle\u001b[39;00m\n\u001b[0;32m     <a href='vscode-notebook-cell:/d%3A/FHNW_Medical_Informatics/Python/Python_Learn/Q_C_Project/PSONN.ipynb#X15sZmlsZQ%3D%3D?line=16'>17</a>\u001b[0m \u001b[39mreturn\u001b[39;00m np\u001b[39m.\u001b[39marray(j)\n",
      "\u001b[1;32md:\\FHNW_Medical_Informatics\\Python\\Python_Learn\\Q_C_Project\\PSONN.ipynb Cell 17\u001b[0m line \u001b[0;36m1\n\u001b[0;32m      <a href='vscode-notebook-cell:/d%3A/FHNW_Medical_Informatics/Python/Python_Learn/Q_C_Project/PSONN.ipynb#X15sZmlsZQ%3D%3D?line=1'>2</a>\u001b[0m \u001b[39m\u001b[39m\u001b[39m\"\"\"Higher-level method to do forward_prop in the\u001b[39;00m\n\u001b[0;32m      <a href='vscode-notebook-cell:/d%3A/FHNW_Medical_Informatics/Python/Python_Learn/Q_C_Project/PSONN.ipynb#X15sZmlsZQ%3D%3D?line=2'>3</a>\u001b[0m \u001b[39mwhole swarm.\u001b[39;00m\n\u001b[0;32m      <a href='vscode-notebook-cell:/d%3A/FHNW_Medical_Informatics/Python/Python_Learn/Q_C_Project/PSONN.ipynb#X15sZmlsZQ%3D%3D?line=3'>4</a>\u001b[0m \n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     <a href='vscode-notebook-cell:/d%3A/FHNW_Medical_Informatics/Python/Python_Learn/Q_C_Project/PSONN.ipynb#X15sZmlsZQ%3D%3D?line=12'>13</a>\u001b[0m \u001b[39m    The computed loss for each particle\u001b[39;00m\n\u001b[0;32m     <a href='vscode-notebook-cell:/d%3A/FHNW_Medical_Informatics/Python/Python_Learn/Q_C_Project/PSONN.ipynb#X15sZmlsZQ%3D%3D?line=13'>14</a>\u001b[0m \u001b[39m\"\"\"\u001b[39;00m\n\u001b[0;32m     <a href='vscode-notebook-cell:/d%3A/FHNW_Medical_Informatics/Python/Python_Learn/Q_C_Project/PSONN.ipynb#X15sZmlsZQ%3D%3D?line=14'>15</a>\u001b[0m n_particles \u001b[39m=\u001b[39m x\u001b[39m.\u001b[39mshape[\u001b[39m0\u001b[39m]\n\u001b[1;32m---> <a href='vscode-notebook-cell:/d%3A/FHNW_Medical_Informatics/Python/Python_Learn/Q_C_Project/PSONN.ipynb#X15sZmlsZQ%3D%3D?line=15'>16</a>\u001b[0m j \u001b[39m=\u001b[39m [forward_prop(x[i]) \u001b[39mfor\u001b[39;00m i \u001b[39min\u001b[39;00m \u001b[39mrange\u001b[39m(n_particles)] \u001b[39m#for loop to calculate loss for each particle\u001b[39;00m\n\u001b[0;32m     <a href='vscode-notebook-cell:/d%3A/FHNW_Medical_Informatics/Python/Python_Learn/Q_C_Project/PSONN.ipynb#X15sZmlsZQ%3D%3D?line=16'>17</a>\u001b[0m \u001b[39mreturn\u001b[39;00m np\u001b[39m.\u001b[39marray(j)\n",
      "\u001b[1;32md:\\FHNW_Medical_Informatics\\Python\\Python_Learn\\Q_C_Project\\PSONN.ipynb Cell 17\u001b[0m line \u001b[0;36m1\n\u001b[0;32m      <a href='vscode-notebook-cell:/d%3A/FHNW_Medical_Informatics/Python/Python_Learn/Q_C_Project/PSONN.ipynb#X15sZmlsZQ%3D%3D?line=1'>2</a>\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mforward_prop\u001b[39m(params):\n\u001b[0;32m      <a href='vscode-notebook-cell:/d%3A/FHNW_Medical_Informatics/Python/Python_Learn/Q_C_Project/PSONN.ipynb#X15sZmlsZQ%3D%3D?line=2'>3</a>\u001b[0m \u001b[39m    \u001b[39m\u001b[39m\"\"\"Forward propagation as objective function\u001b[39;00m\n\u001b[0;32m      <a href='vscode-notebook-cell:/d%3A/FHNW_Medical_Informatics/Python/Python_Learn/Q_C_Project/PSONN.ipynb#X15sZmlsZQ%3D%3D?line=3'>4</a>\u001b[0m \n\u001b[0;32m      <a href='vscode-notebook-cell:/d%3A/FHNW_Medical_Informatics/Python/Python_Learn/Q_C_Project/PSONN.ipynb#X15sZmlsZQ%3D%3D?line=4'>5</a>\u001b[0m \u001b[39m    This computes for the forward propagation of the neural network, as\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     <a href='vscode-notebook-cell:/d%3A/FHNW_Medical_Informatics/Python/Python_Learn/Q_C_Project/PSONN.ipynb#X15sZmlsZQ%3D%3D?line=16'>17</a>\u001b[0m \u001b[39m        The computed negative log-likelihood loss given the parameters\u001b[39;00m\n\u001b[0;32m     <a href='vscode-notebook-cell:/d%3A/FHNW_Medical_Informatics/Python/Python_Learn/Q_C_Project/PSONN.ipynb#X15sZmlsZQ%3D%3D?line=17'>18</a>\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n\u001b[1;32m---> <a href='vscode-notebook-cell:/d%3A/FHNW_Medical_Informatics/Python/Python_Learn/Q_C_Project/PSONN.ipynb#X15sZmlsZQ%3D%3D?line=18'>19</a>\u001b[0m     logits \u001b[39m=\u001b[39m logits_function(params)\n\u001b[0;32m     <a href='vscode-notebook-cell:/d%3A/FHNW_Medical_Informatics/Python/Python_Learn/Q_C_Project/PSONN.ipynb#X15sZmlsZQ%3D%3D?line=20'>21</a>\u001b[0m     \u001b[39m# Compute for the softmax of the logits\u001b[39;00m\n\u001b[0;32m     <a href='vscode-notebook-cell:/d%3A/FHNW_Medical_Informatics/Python/Python_Learn/Q_C_Project/PSONN.ipynb#X15sZmlsZQ%3D%3D?line=21'>22</a>\u001b[0m     exp_scores \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39mexp(logits)\n",
      "\u001b[1;32md:\\FHNW_Medical_Informatics\\Python\\Python_Learn\\Q_C_Project\\PSONN.ipynb Cell 17\u001b[0m line \u001b[0;36m1\n\u001b[0;32m     <a href='vscode-notebook-cell:/d%3A/FHNW_Medical_Informatics/Python/Python_Learn/Q_C_Project/PSONN.ipynb#X15sZmlsZQ%3D%3D?line=15'>16</a>\u001b[0m W1 \u001b[39m=\u001b[39m p[\u001b[39m0\u001b[39m:\u001b[39m80\u001b[39m]\u001b[39m.\u001b[39mreshape((n_inputs,n_hidden))\n\u001b[0;32m     <a href='vscode-notebook-cell:/d%3A/FHNW_Medical_Informatics/Python/Python_Learn/Q_C_Project/PSONN.ipynb#X15sZmlsZQ%3D%3D?line=16'>17</a>\u001b[0m b1 \u001b[39m=\u001b[39m p[\u001b[39m80\u001b[39m:\u001b[39m100\u001b[39m]\u001b[39m.\u001b[39mreshape((n_hidden,))\n\u001b[1;32m---> <a href='vscode-notebook-cell:/d%3A/FHNW_Medical_Informatics/Python/Python_Learn/Q_C_Project/PSONN.ipynb#X15sZmlsZQ%3D%3D?line=17'>18</a>\u001b[0m W2 \u001b[39m=\u001b[39m p[\u001b[39m100\u001b[39;49m:\u001b[39m160\u001b[39;49m]\u001b[39m.\u001b[39;49mreshape((n_hidden,n_classes))\n\u001b[0;32m     <a href='vscode-notebook-cell:/d%3A/FHNW_Medical_Informatics/Python/Python_Learn/Q_C_Project/PSONN.ipynb#X15sZmlsZQ%3D%3D?line=18'>19</a>\u001b[0m b2 \u001b[39m=\u001b[39m p[\u001b[39m160\u001b[39m:\u001b[39m163\u001b[39m]\u001b[39m.\u001b[39mreshape((n_classes,))\n\u001b[0;32m     <a href='vscode-notebook-cell:/d%3A/FHNW_Medical_Informatics/Python/Python_Learn/Q_C_Project/PSONN.ipynb#X15sZmlsZQ%3D%3D?line=20'>21</a>\u001b[0m \u001b[39m# Perform forward propagation\u001b[39;00m\n",
      "\u001b[1;31mValueError\u001b[0m: cannot reshape array of size 42 into shape (20,2)"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# Initialize swarm\n",
    "options = {'c1': 0.5, 'c2': 0.3, 'w':0.9}\n",
    "\n",
    "# Call instance of PSO\n",
    "dimensions = (n_inputs * n_hidden) + (n_hidden * n_classes) + n_hidden + n_classes\n",
    "optimizer = ps.single.GlobalBestPSO(n_particles=100, dimensions=dimensions, options=options)\n",
    "\n",
    "# Perform optimization\n",
    "cost, pos = optimizer.optimize(f, iters=2000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict(pos):\n",
    "    \"\"\"\n",
    "    Use the trained weights to perform class predictions.\n",
    "\n",
    "    Inputs\n",
    "    ------\n",
    "    pos: numpy.ndarray\n",
    "        Position matrix found by the swarm. Will be rolled\n",
    "        into weights and biases.\n",
    "    \"\"\"\n",
    "    logits = logits_function(pos)\n",
    "    y_pred = np.argmax(logits, axis=1)\n",
    "    return y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(predict(pos) == y_train).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#visualization\n",
    "#import modules\n",
    "\n",
    "#import additional libraries\n",
    "from pyswarms.utils.plotters import (plot_cost_history, plot_contour, plot_surface)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_cost_history(cost_history= optimizer.cost_history)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#animated swarm\n",
    "from pyswarms.utils.plotters.formatters import Mesher\n",
    "from pyswarms.utils.functions import single_obj as fx\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize mesher with sphere function\n",
    "m = Mesher(func=fx.sphere)\n",
    "                     \n",
    "#set the position of the particles swarm in one of the dimension \n",
    "position = np.array(optimizer.pos_history)\n",
    "position = position[:,:, 220:222]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Plot 2D Contour\n",
    "#Make animation\n",
    "anim = plot_contour(pos_history=position,\n",
    "                            mesher=m,\n",
    "                            mark=(0,0)) #red cross in the middle  \n",
    "\n",
    "anim.save('2d.gif')                          "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#plot 2D contour with optimizer based on velocity history\n",
    "position = np.array(optimizer.velocity_history)\n",
    "position = position[:,:, 220:222]\n",
    "anim = plot_contour(pos_history=position,\n",
    "                            mesher=m,\n",
    "                            mark=(0,0)) #red cross in the middle  \n",
    "\n",
    "anim.save('2d_velocity.gif')  "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
